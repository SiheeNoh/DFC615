{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DFC615_NLP_Task1_Movie_nsmc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMESZGLir52QwoEmnr7CUdQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiheeNoh/DFC615/blob/master/DFC615_NLP_Task1_Movie_nsmc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52oTnVVdztqC",
        "colab_type": "text"
      },
      "source": [
        "1. 한국어 감정 분석 \n",
        "  • 영화 리뷰를 바탕으로 긍정/부정을 예측 \n",
        "  • NSMC 다운로드 :  https://github.com/e9t/nsmc\n",
        "\n",
        "\n",
        "감성 분석\n",
        " 나이브 베이즈 분류 모형을 이용하여 문서에 대한 감성 분석(sentiment analysis) 실행\n",
        "  > 감성 분석이란 문서에 대해 좋다(positive) 혹은 나쁘다(negative)는 평가를 내리는 것\n",
        " 샘플 데이터로는 github에 올려져 있는 네이버 영화 감상평에 대한 감성 분석 예제 이용\n",
        "  > https://github.com/e9t/nsmc\n",
        "\n",
        "\n",
        "Movie_nsmc\n",
        "\n",
        "데이터 전처리 우선 데이터를 다운로드 받아서 읽기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJcrlZ4GVsIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "8be7e742-627d-4022-baac-7f2b915aa742"
      },
      "source": [
        "%%time\n",
        "!rm -f ko_data.txt ratings_train.txt ratings_test.txt\n",
        "\n",
        "!wget -nc https://raw.githubusercontent.com/SiheeNoh/DFC615/master/ko_data.txt\n",
        "!wget -nc https://raw.githubusercontent.com/SiheeNoh/DFC615/master/ratings_train.txt\n",
        "!wget -nc https://raw.githubusercontent.com/SiheeNoh/DFC615/master/ratings_test.txt\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-25 07:32:11--  https://raw.githubusercontent.com/SiheeNoh/DFC615/master/ko_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 622720 (608K) [text/plain]\n",
            "Saving to: ‘ko_data.txt’\n",
            "\n",
            "\rko_data.txt           0%[                    ]       0  --.-KB/s               \rko_data.txt         100%[===================>] 608.12K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2020-06-25 07:32:11 (10.6 MB/s) - ‘ko_data.txt’ saved [622720/622720]\n",
            "\n",
            "--2020-06-25 07:32:13--  https://raw.githubusercontent.com/SiheeNoh/DFC615/master/ratings_train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14628807 (14M) [text/plain]\n",
            "Saving to: ‘ratings_train.txt’\n",
            "\n",
            "ratings_train.txt   100%[===================>]  13.95M  55.4MB/s    in 0.3s    \n",
            "\n",
            "2020-06-25 07:32:13 (55.4 MB/s) - ‘ratings_train.txt’ saved [14628807/14628807]\n",
            "\n",
            "--2020-06-25 07:32:15--  https://raw.githubusercontent.com/SiheeNoh/DFC615/master/ratings_test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4893335 (4.7M) [text/plain]\n",
            "Saving to: ‘ratings_test.txt’\n",
            "\n",
            "ratings_test.txt    100%[===================>]   4.67M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-06-25 07:32:15 (34.0 MB/s) - ‘ratings_test.txt’ saved [4893335/4893335]\n",
            "\n",
            "CPU times: user 65.9 ms, sys: 21.6 ms, total: 87.4 ms\n",
            "Wall time: 7.79 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cN9GQAVdBRJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "outputId": "a0b6e362-623e-449d-9c16-b640d0d56095"
      },
      "source": [
        "%matplotlib inline \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import folium\n",
        "import plotly.express as px\n",
        "import cufflinks as cf\n",
        "cf.go_offline(connected=True)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GnUp-Iwz5hY",
        "colab_type": "text"
      },
      "source": [
        "유니코드로 인코딩하며 읽기 위해 codecs 패키지를 사용. 읽어들인 결과는 유니코드 문자열이 됨."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PgsAUp9R7AJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import codecs\n",
        "with codecs.open('ratings_train.txt', 'r', encoding='utf-8') as f1:\n",
        "    data_train = [line.split('\\t') for line in f1.read().splitlines()]\n",
        "    data_train = data_train[1:]   # header 제외\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeIgB4lHTdAH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d18f51b9-2c3c-4e08-bc4f-ab7cbd6934db"
      },
      "source": [
        "len(data_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5xGNgv0MiYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f65b080-ce88-4947-fa33-52cecb7ab541"
      },
      "source": [
        "data_train[:1]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['9976970', '아 더빙.. 진짜 짜증나네요 목소리', '0']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW_OMsqj0LyI",
        "colab_type": "text"
      },
      "source": [
        "이 데이터는 번호, 내용, 평점으로 이루져 있으므로 내용을 X, 평점을 y로 저장."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzaI4WRLQ_WV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "650c2e0a-8d0d-41e7-f517-3bd8a27dc18d"
      },
      "source": [
        "from pprint import pprint\n",
        "pprint(data_train[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['3819312', '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqi_3y8oRBCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "X = list(zip(*data_train))[1]\n",
        "y = np.array(list(zip(*data_train))[2], dtype=int)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-jXsrFl0Pig",
        "colab_type": "text"
      },
      "source": [
        "다항 나이브 베이즈 모형으로 학습. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYB2de4GRlOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "model1 = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('mb', MultinomialNB()),\n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHjTPwSJRnOZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "6a0d09b6-0d4e-43ef-9b24-b33316af7f49"
      },
      "source": [
        "%%time\n",
        "model1.fit(X, y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.5 s, sys: 72.2 ms, total: 2.57 s\n",
            "Wall time: 2.59 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('mb',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZEr-BRRRvLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import codecs\n",
        "with codecs.open(\"ratings_test.txt\", encoding='utf-8') as f2:\n",
        "    data_test = [line.split('\\t') for line in f2.read().splitlines()]\n",
        "    data_test = data_test[1:]   # header 제외"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhWmBwMBYsnH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48f15159-8b9f-4934-bcb2-99b3b62fae24"
      },
      "source": [
        "len(data_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRoj_cgLRxy6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "6d94e58f-79e8-4424-fe8c-8cde818b79c5"
      },
      "source": [
        "X_test = list(zip(*data_test))[1]\n",
        "y_test = np.array(list(zip(*data_test))[2], dtype=int)\n",
        "\n",
        "print(classification_report(y_test, model1.predict(X_test)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.84      0.83     24827\n",
            "           1       0.84      0.81      0.82     25173\n",
            "\n",
            "    accuracy                           0.83     50000\n",
            "   macro avg       0.83      0.83      0.83     50000\n",
            "weighted avg       0.83      0.83      0.83     50000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwSDyWkrcXv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import codecs\n",
        "with codecs.open(\"ko_data.txt\", encoding='cp949') as f3:\n",
        "    data_real = [line.split('\\t') for line in f3.read().splitlines()]\n",
        "    data_real = data_real[1:]   # header 제외"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aqxv--AecX_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_real = list(zip(*data_real))[1]\n",
        "result = model1.predict(X_test_real)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy8XwC5FjlAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 0\n",
        "for i in data_real :\n",
        "  i.append(result[idx])\n",
        "  idx+=1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7FmPSypiz6B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22d1aadb-4120-4e04-eb37-15e3a8c5b6ee"
      },
      "source": [
        "str(data_real[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"['0', '정말 많이 울었던 영화입니다.', 1]\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lidMrtqQ2H5L",
        "colab_type": "text"
      },
      "source": [
        "결과값 저장(나이브 베이즈 방법)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVzaAL4AYblH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ko_data_result = open(\"ko_data_result.txt\", 'w')\n",
        "\n",
        "idx = 0\n",
        "for i in data_real :\n",
        "  ko_data_result.write(str(data_real[idx][0])+'\\t'+str(data_real[idx][2])+'\\n')\n",
        "  idx+=1\n",
        "ko_data_result.close()\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6_0eP0pYdyD",
        "colab_type": "text"
      },
      "source": [
        "Tf-idf 방법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC9AsSWHR0vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "model2 = Pipeline([\n",
        "    ('vect', TfidfVectorizer()),\n",
        "    ('mb', MultinomialNB()),\n",
        "])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKa-JUoaR2wZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "29c12591-5ce1-413a-9977-21f0f31392e5"
      },
      "source": [
        "%%time\n",
        "model2.fit(X, y)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.54 s, sys: 73.4 ms, total: 2.62 s\n",
            "Wall time: 2.64 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('mb',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_L4EeqyR5vQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "12a816a9-3793-48e5-e24d-328c26516c3d"
      },
      "source": [
        "print(classification_report(y_test, model2.predict(X_test)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.84      0.83     24827\n",
            "           1       0.84      0.81      0.83     25173\n",
            "\n",
            "    accuracy                           0.83     50000\n",
            "   macro avg       0.83      0.83      0.83     50000\n",
            "weighted avg       0.83      0.83      0.83     50000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od7nk483R8fV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a4faa0f-aed1-4f6d-c29e-c68317fe945b"
      },
      "source": [
        "!pip install mecab-python3\n",
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk python-dev python3-dev\n",
        "!pip3 install JPype1-py3\n",
        "!pip3 install konlpy\n",
        "!JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mecab-python3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/49/b55a839a77189042960bf96490640c44816073f917d489acbc5d79fa5cc3/mecab_python3-0.996.5-cp36-cp36m-manylinux2010_x86_64.whl (17.1MB)\n",
            "\u001b[K     |████████████████████████████████| 17.1MB 243kB/s \n",
            "\u001b[?25hInstalling collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-0.996.5\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
            "Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [185 kB]\n",
            "Get:13 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:14 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [38.7 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [961 kB]\n",
            "Get:17 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,841 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [87.2 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,270 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,398 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [20.7 kB]\n",
            "Get:22 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [888 kB]\n",
            "Fetched 6,963 kB in 4s (1,705 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-dev is already the newest version (2.7.15~rc1-1).\n",
            "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
            "g++ set to manually installed.\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n",
            "  openjdk-8-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source visualvm icedtea-8-plugin libnss-mdns\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless\n",
            "  openjdk-8-jre openjdk-8-jre-headless x11-utils\n",
            "0 upgraded, 10 newly installed, 0 to remove and 62 not upgraded.\n",
            "Need to get 40.7 MB of archives.\n",
            "After this operation, 153 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u252-b09-1~18.04 [27.5 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u252-b09-1~18.04 [69.8 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u252-b09-1~18.04 [8,250 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u252-b09-1~18.04 [1,622 kB]\n",
            "Fetched 40.7 MB in 3s (11.9 MB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 144328 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../1-fonts-dejavu-core_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../2-fonts-dejavu-extra_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../3-x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../4-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../5-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../6-openjdk-8-jre-headless_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../7-openjdk-8-jre_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u252-b09-1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../8-openjdk-8-jdk-headless_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
            "Preparing to unpack .../9-openjdk-8-jdk_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk:amd64 (8u252-b09-1~18.04) ...\n",
            "Setting up fonts-dejavu-core (2.37-1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Setting up openjdk-8-jre:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Setting up openjdk-8-jdk:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting JPype1-py3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/81/63f5e4202c598f362ee4684b41890f993d6e58309c5d90703f570ab85f62/JPype1-py3-0.5.5.4.tar.gz (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 3.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: JPype1-py3\n",
            "  Building wheel for JPype1-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for JPype1-py3: filename=JPype1_py3-0.5.5.4-cp36-cp36m-linux_x86_64.whl size=2676451 sha256=ad6adcfb5231ec4c31f36f2a282862dd815185cd92877fc233d5c7ef08928122\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/37/1f/1015d908d12a0e9b239543d031fda0cded9823aa1306939541\n",
            "Successfully built JPype1-py3\n",
            "Installing collected packages: JPype1-py3\n",
            "Successfully installed JPype1-py3-0.5.5.4\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/9b/e115101a833605b3c0e6f3a2bc1f285c95aaa1d93ab808314ca1bde63eed/JPype1-0.7.5-cp36-cp36m-manylinux2010_x86_64.whl (3.6MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6MB 46.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2020.4.5.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: beautifulsoup4, tweepy, colorama, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-0.7.5 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2WpYGlfYp1Q",
        "colab_type": "text"
      },
      "source": [
        "형태소 분석기 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu99tXstU53_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "pos_tagger = Okt()\n",
        "\n",
        "def tokenize_pos(doc):\n",
        "    return ['/'.join(t) for t in pos_tagger.pos(doc)]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPA7Jvn3U8BX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = Pipeline([\n",
        "    ('vect', CountVectorizer(tokenizer=tokenize_pos)),\n",
        "    ('mb', MultinomialNB()),\n",
        "])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4YNeWQzU9dd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "6f047773-abaa-4b09-dabf-03aaee840978"
      },
      "source": [
        "%%time\n",
        "model3.fit(X, y)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6min 12s, sys: 1.39 s, total: 6min 14s\n",
            "Wall time: 6min\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function tokenize_pos at 0x7fae75de9378>,\n",
              "                                 vocabulary=None)),\n",
              "                ('mb',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KYI7dnOWXXb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "3794ec9d-60ec-4965-c1bb-79ccac62177a"
      },
      "source": [
        "print(classification_report(y_test, model3.predict(X_test)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.85     24827\n",
            "           1       0.86      0.85      0.85     25173\n",
            "\n",
            "    accuracy                           0.85     50000\n",
            "   macro avg       0.85      0.85      0.85     50000\n",
            "weighted avg       0.85      0.85      0.85     50000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XRo_-oMYuT1",
        "colab_type": "text"
      },
      "source": [
        "(1,2)-gram 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHz_4I2ZXWr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model4 = Pipeline([\n",
        "    ('vect', TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1, 2))),\n",
        "    ('mb', MultinomialNB()),\n",
        "])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyxbGp8eXZoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "7e383dce-aa99-4f4a-9491-6b8c233700cd"
      },
      "source": [
        "%%time\n",
        "model4.fit(X, y)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9min 13s, sys: 1.54 s, total: 9min 14s\n",
            "Wall time: 9min 6s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function tokenize_pos at 0x7fae75de9378>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('mb',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w57-GUQIaDeD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "e3564e91-3b67-4093-e508-fe7d670d94c8"
      },
      "source": [
        "print(classification_report(y_test, model4.predict(X_test)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87     24827\n",
            "           1       0.87      0.86      0.87     25173\n",
            "\n",
            "    accuracy                           0.87     50000\n",
            "   macro avg       0.87      0.87      0.87     50000\n",
            "weighted avg       0.87      0.87      0.87     50000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDlHQn-39dnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import codecs\n",
        "with codecs.open(\"ko_data.txt\", encoding='cp949') as f3:\n",
        "    data_real_2 = [line.split('\\t') for line in f3.read().splitlines()]\n",
        "    data_real_2 = data_real_2[1:]   # header 제외"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feQ4tIWz8Z32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_2 = list(zip(*data_real_2))[1]\n",
        "result_ngram = model4.predict(X_test_2)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3yxvrOa91Kg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0c69362c-5635-48e5-d70f-b57eb37e1faa"
      },
      "source": [
        "data_real_2[:3]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['0', '정말 많이 울었던 영화입니다.'],\n",
              " ['1', '시간 낭비예요.'],\n",
              " ['2', '포스터를 저렇게밖에 만들지 못했던 제작자의 소심함에 침을 뱉고 싶다.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkTE6Emo9yLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = 0\n",
        "for i in data_real_2 :\n",
        "  i.append(result_ngram[idx])\n",
        "  idx+=1"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEDk2-YfY1dv",
        "colab_type": "text"
      },
      "source": [
        "결과 추출 : ngram (F1-score 값이 가장 좋음)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NSM4uVw99O5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ko_data_result_ngram = open(\"ko_data_result_ngram.txt\", 'w')\n",
        "\n",
        "idx = 0\n",
        "for i in data_real_2 :\n",
        "  ko_data_result_ngram.write(str(data_real_2[idx][0])+'\\t'+str(data_real_2[idx][2])+'\\n')\n",
        "  idx+=1\n",
        "ko_data_result_ngram.close()"
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}